#!/usr/bin/env python3
"""
Test script to verify the improved model detection logic.
"""

import logging
from config import get_active_vision_model, get_current_model_name

# Configure logging to see the detection process
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def test_model_detection():
    """Test the improved model detection."""
    
    print("üöÄ Testing Improved Model Detection")
    print("=" * 50)
    
    # Test the active vision model detection
    print("1Ô∏è‚É£ Testing get_active_vision_model()...")
    detected_model = get_active_vision_model()
    print(f"   Result: {detected_model}")
    
    # Test the current model name function
    print("\n2Ô∏è‚É£ Testing get_current_model_name()...")
    current_model = get_current_model_name()
    print(f"   Result: {current_model}")
    
    # Verify they match
    print(f"\n3Ô∏è‚É£ Verification:")
    if detected_model == current_model:
        print(f"   ‚úÖ Both functions return the same model: {detected_model}")
    else:
        print(f"   ‚ö†Ô∏è  Functions return different models:")
        print(f"      get_active_vision_model(): {detected_model}")
        print(f"      get_current_model_name(): {current_model}")
    
    # Check if it's the expected model
    print(f"\n4Ô∏è‚É£ Model Analysis:")
    if detected_model:
        if "gemma" in detected_model.lower():
            print(f"   ‚úÖ Correctly detected Gemma model: {detected_model}")
            print(f"   ‚ÑπÔ∏è  Note: Gemma has vision capabilities but may be limited compared to dedicated vision models")
        elif "vision" in detected_model.lower():
            print(f"   ‚úÖ Detected dedicated vision model: {detected_model}")
        else:
            print(f"   ‚ö†Ô∏è  Detected model may have limited vision capabilities: {detected_model}")
    else:
        print(f"   ‚ùå No model detected - check LM Studio connection")
    
    print(f"\n5Ô∏è‚É£ Summary:")
    if detected_model:
        print(f"   ‚úÖ Model detection is working correctly")
        print(f"   üéØ Active model: {detected_model}")
        print(f"   üí° The system will now use the currently loaded model instead of guessing")
    else:
        print(f"   ‚ùå Model detection failed")
        print(f"   üí° Check that LM Studio is running and has a model loaded")

if __name__ == "__main__":
    test_model_detection()